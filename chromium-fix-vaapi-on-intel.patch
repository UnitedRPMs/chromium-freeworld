--- a/media/gpu/vaapi/vaapi_video_decode_accelerator.cc
+++ b/media/gpu/vaapi/vaapi_video_decode_accelerator.cc
@@ -66,6 +66,7 @@ void ReportToUMA(VAVDADecoderFailure fai
                             VAVDA_DECODER_FAILURES_MAX + 1);
 }
 
+#if defined(OS_ANDROID) || defined(OS_CHROMEOS)
 // Returns true if the CPU is an Intel Gemini Lake or later (including Kaby
 // Lake) Cpu platform id's are referenced from the following file in kernel
 // source arch/x86/include/asm/intel-family.h
@@ -78,6 +79,7 @@ bool IsGeminiLakeOrLater() {
       cpuid.model() >= kGeminiLakeModelId;
   return is_geminilake_or_later;
 }
+#endif 
 
 }  // namespace
 
@@ -1155,6 +1157,8 @@ VaapiVideoDecodeAccelerator::DecideBuffe
   if (output_mode_ == VideoDecodeAccelerator::Config::OutputMode::IMPORT)
     return BufferAllocationMode::kNormal;
 
+#if defined(OS_ANDROID) || defined(OS_CHROMEOS)
+  // Move this to chromeOs only as it is causing problem in some intel linux drivers
   // On Gemini Lake, Kaby Lake and later we can pass to libva the client's
   // PictureBuffers to decode onto, which skips the use of the Vpp unit and its
   // associated format reconciliation copy, avoiding all internal buffer
@@ -1163,6 +1163,9 @@
   // of frames needed by the client pipeline (see b/133733739).
   // TODO(crbug.com/911754): Enable for VP9 Profile 2.
   if (IsGeminiLakeOrLater() &&
+#if defined(OS_LINUX)
+      false &&
+#endif
       (profile_ == VP9PROFILE_PROFILE0 || profile_ == VP8PROFILE_ANY)) {
     // Add one to the reference frames for the one being currently egressed, and
     // an extra allocation for both |client_| and |decoder_|, see
@@ -1171,6 +1175,7 @@ VaapiVideoDecodeAccelerator::DecideBuffe
       num_extra_pics_ = 3;
     return BufferAllocationMode::kNone;
   }
+#endif 
 
   // If we're here, we have to use the Vpp unit and allocate buffers for
   // |decoder_|; usually we'd have to allocate the |decoder_|s
